apiVersion: v1
kind: ServiceAccount
metadata:
  name: filebeat
  namespace: elkstack
  labels:
    app: filebeat
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: filebeat
  labels:
    app: filebeat
    addonmanager.kubernetes.io/mode: Reconcile
rules:
- apiGroups:
  - ""
  resources:
  - "namespaces"
  - "pods"
  verbs:
  - "get"
  - "watch"
  - "list"
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: filebeat
  labels:
    app: filebeat
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
- kind: ServiceAccount
  name: filebeat
  namespace: elkstack
  apiGroup: ""
roleRef:
  kind: ClusterRole
  name: filebeat
  apiGroup: ""
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
  namespace: elkstack
  labels:
    app: filebeat
data:
  filebeat.yml: |-
    # To enable hints based autodiscover, remove `filebeat.inputs` configuration and uncomment this:
    filebeat.autodiscover:
      providers:
        - type: kubernetes
          node: ${NODE_NAME}
          templates:
            - condition:
                equals:
                  kubernetes.namespace: default    #修改需要收集日志的名称空间
              config:
                - type: log
                  containers.ids:
                    - "${data.kubernetes.container.id}"
                  paths:
                    - /var/lib/kubelet/pods/${data.kubernetes.pod.uid}/volumes/kubernetes.io~empty-dir/logs/**/*.log
                  multiline:
                    pattern: '\d{4}-\d{2}-\d{2}'    #日志格式的正则表达式，根据日志自定义修改，此处是nginx错>误日志。开头2021/02/01
                    negate: true
                    match: after
                  tail_files: true
                  fields:
                    type: shm_java
        - type: kubernetes
          node: ${NODE_NAME}
          templates:
            - condition:
                equals:
                  kubernetes.namespace: nginx    #修改需要收集日志的名称空间
              config:
                - type: log
                  containers.ids:
                    - "${data.kubernetes.container.id}"
                  paths:
                    - /var/lib/kubelet/pods/${data.kubernetes.pod.uid}/volumes/kubernetes.io~empty-dir/logs/*.log
                  multiline:
                    pattern: '((2[0-4]\d|25[0-5]|[01]?\d\d?)\.){3}(2[0-4]\d|25[0-5]|[01]?\d\d?)'    #日志格式的正则表达式，根据日志自定义修改，此处是nginx错误日志。开头2021/02/01
                    negate: true
                    match: after
                  tail_files: true
                  fields:
                    type: shm_nginx

    processors:
      - copy_fields:
          fields:
            - from: log.file.path
              to: app_logpath
            - from: kubernetes.labels.app
              to: app_name
            - from: kubernetes.namespace
              to: app_namespace
            - from: kubernetes.container.image
              to: app_image
            - from: kubernetes.container.name
              to: app_containername
            - from: kubernetes.node.name
              to: app_nodename
            - from: kubernetes.pod.name
              to: app_podname
            - from: fields.type
              to: app_type
          fail_on_error: false
          ignore_missing: true
      - drop_fields:
          fields: ["ecs", "host", "agent", "log", "input", "kubernetes", "fields"]
    output:
      kafka:
        enabled: true
        hosts: ["kafka:9092"]
        topic: '%{[app_name]}'
        partition.round_robin:
          reachable_only: true
        keep-alive: 120
        required_acks: 1
        worker: 2
        compression: gzip
        max_message_bytes: 10000000

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: filebeat
  namespace: elkstack
  labels:
    app: filebeat
spec:
  selector:
    matchLabels:
      app: filebeat
  template:
    metadata:
      labels:
        app: filebeat
    spec:
      serviceAccountName: filebeat
      terminationGracePeriodSeconds: 30
      #hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: filebeat
        image: elastic/filebeat:7.9.0
        args: [
          "-c", "/etc/filebeat.yml",
          "-e",
        ]
        env:
        #- name: ELASTICSEARCH_HOST
        #  value: elasticsearch
        #- name: ELASTICSEARCH_PORT
        #  value: "9200"
        #- name: ELASTICSEARCH_USERNAME
        #  value: elastic
        #- name: ELASTICSEARCH_PASSWORD
        #  value: changeme
        #- name: ELASTIC_CLOUD_ID
        #  value:
        #- name: ELASTIC_CLOUD_AUTH
        #  value:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: TZ
          value: "Asia/Shanghai"
        securityContext:
          runAsUser: 0
          # If using Red Hat OpenShift uncomment this:
          #privileged: true
        resources:
          limits:
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 100Mi
        volumeMounts:
        - name: config
          mountPath: /etc/filebeat.yml
          readOnly: true
          subPath: filebeat.yml
        - name: data
          mountPath: /usr/share/filebeat/data
        - name: varlibkubeletpods
          mountPath: /var/lib/kubelet/pods
          readOnly: true
      volumes:
      - name: config
        configMap:
          defaultMode: 0640
          name: filebeat-config
      - name: varlibkubeletpods
        hostPath:
          path: /var/lib/kubelet/pods
      # data folder stores a registry of read status for all files, so we don't send everything again on a Filebeat pod restart
      - name: data
        hostPath:
          # When filebeat runs as non-root user, this directory needs to be writable by group (g+w).
          path: /var/lib/filebeat-data
          type: DirectoryOrCreate
